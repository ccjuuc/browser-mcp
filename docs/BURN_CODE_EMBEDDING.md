# ä½¿ç”¨ Burn æ¡†æ¶è¿›è¡Œä»£ç å‘é‡åŒ–ï¼šæ¨¡å‹é€‰æ‹©ä¸å®ç°æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æ¨èçš„ä»£ç å‘é‡åŒ–æ¨¡å‹](#æ¨èçš„ä»£ç å‘é‡åŒ–æ¨¡å‹)
3. [æ¨¡å‹å¯¹æ¯”](#æ¨¡å‹å¯¹æ¯”)
4. [Burn ä¸­çš„å®ç°æ–¹æ¡ˆ](#burn-ä¸­çš„å®ç°æ–¹æ¡ˆ)
5. [ä»£ç ç¤ºä¾‹](#ä»£ç ç¤ºä¾‹)
6. [æ¨¡å‹è½¬æ¢æŒ‡å—](#æ¨¡å‹è½¬æ¢æŒ‡å—)
7. [æ€§èƒ½å¯¹æ¯”](#æ€§èƒ½å¯¹æ¯”)
8. [è¿ç§»å»ºè®®](#è¿ç§»å»ºè®®)

---

## æ¦‚è¿°

å½“å‰é¡¹ç›®ä½¿ç”¨ **CodeBERT (microsoft/codebert-base)** è¿›è¡Œä»£ç å‘é‡åŒ–ã€‚å¦‚æœè¿ç§»åˆ° Burn æ¡†æ¶ï¼Œæœ‰ä»¥ä¸‹å‡ ç§æ–¹æ¡ˆï¼š

### å½“å‰å®ç° (Candle)
- **æ¨¡å‹**: CodeBERT (microsoft/codebert-base)
- **æ¡†æ¶**: Candle
- **ç»´åº¦**: 768
- **æ ¼å¼**: SafeTensors + config.json

### Burn å®ç°é€‰é¡¹
1. **ç›´æ¥ä½¿ç”¨ CodeBERT** (æ¨è)
2. **ä½¿ç”¨ GraphCodeBERT** (æ›´å¥½çš„ä»£ç ç†è§£)
3. **ä½¿ç”¨ CodeT5** (ç¼–ç å™¨-è§£ç å™¨æ¶æ„)
4. **ä½¿ç”¨ StarCoder** (å¤§æ¨¡å‹ï¼Œéœ€è¦æ›´å¤šèµ„æº)

---

## æ¨èçš„ä»£ç å‘é‡åŒ–æ¨¡å‹

### 1. CodeBERT â­â­â­â­â­ (æœ€æ¨è)

**æ¨¡å‹ä¿¡æ¯**:
- **Hugging Face ID**: `microsoft/codebert-base`
- **æ¶æ„**: RoBERTa-based (BERT å˜ä½“)
- **å‚æ•°é‡**: 125M
- **è¾“å‡ºç»´åº¦**: 768
- **æœ€å¤§åºåˆ—é•¿åº¦**: 512
- **è®­ç»ƒæ•°æ®**: 6.4M ä»£ç -æ–‡æ¡£å¯¹

**ä¼˜åŠ¿**:
- âœ… ä¸“ä¸ºä»£ç è®¾è®¡
- âœ… è½»é‡çº§ï¼Œæ¨ç†é€Ÿåº¦å¿«
- âœ… ä¸å½“å‰é¡¹ç›®å®Œå…¨å…¼å®¹
- âœ… åœ¨ä»£ç æœç´¢ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜ç§€

**é€‚ç”¨åœºæ™¯**:
- ä»£ç æœç´¢å’Œæ£€ç´¢
- ä»£ç ç›¸ä¼¼åº¦è®¡ç®—
- ä»£ç åˆ†ç±»
- **æ‚¨çš„é¡¹ç›®**: âœ… å®Œç¾åŒ¹é…

---

### 2. GraphCodeBERT â­â­â­â­

**æ¨¡å‹ä¿¡æ¯**:
- **Hugging Face ID**: `microsoft/graphcodebert-base`
- **æ¶æ„**: CodeBERT + æ•°æ®æµå›¾
- **å‚æ•°é‡**: 125M
- **è¾“å‡ºç»´åº¦**: 768
- **æœ€å¤§åºåˆ—é•¿åº¦**: 512

**ä¼˜åŠ¿**:
- âœ… ç†è§£ä»£ç çš„æ•°æ®æµå’Œæ§åˆ¶æµ
- âœ… åœ¨ä»£ç æœç´¢ä»»åŠ¡ä¸Šä¼˜äº CodeBERT
- âœ… èƒ½æ•è·ä»£ç çš„è¯­ä¹‰ç»“æ„

**åŠ£åŠ¿**:
- âš ï¸ éœ€è¦é¢å¤–çš„å›¾æ„å»ºæ­¥éª¤
- âš ï¸ å®ç°å¤æ‚åº¦æ›´é«˜

**é€‚ç”¨åœºæ™¯**:
- éœ€è¦æ·±åº¦ç†è§£ä»£ç è¯­ä¹‰
- ä»£ç å…‹éš†æ£€æµ‹
- ä»£ç è¡¥å…¨

---

### 3. CodeT5 â­â­â­

**æ¨¡å‹ä¿¡æ¯**:
- **Hugging Face ID**: `Salesforce/codet5-base`
- **æ¶æ„**: T5 (ç¼–ç å™¨-è§£ç å™¨)
- **å‚æ•°é‡**: 220M
- **è¾“å‡ºç»´åº¦**: 768 (ç¼–ç å™¨è¾“å‡º)
- **æœ€å¤§åºåˆ—é•¿åº¦**: 512

**ä¼˜åŠ¿**:
- âœ… æ”¯æŒç”Ÿæˆä»»åŠ¡
- âœ… åœ¨ä»£ç æ‘˜è¦ä»»åŠ¡ä¸Šè¡¨ç°å¥½

**åŠ£åŠ¿**:
- âš ï¸ å‚æ•°é‡æ›´å¤§
- âš ï¸ æ¨ç†é€Ÿåº¦è¾ƒæ…¢
- âš ï¸ å¯¹äºçº¯å‘é‡åŒ–ä»»åŠ¡å¯èƒ½è¿‡åº¦è®¾è®¡

**é€‚ç”¨åœºæ™¯**:
- ä»£ç ç”Ÿæˆ
- ä»£ç æ‘˜è¦
- ä»£ç ç¿»è¯‘

---

### 4. StarCoder â­â­ (ä¸æ¨èç”¨äºå‘é‡åŒ–)

**æ¨¡å‹ä¿¡æ¯**:
- **Hugging Face ID**: `bigcode/starcoder`
- **æ¶æ„**: GPT-style (ä»…è§£ç å™¨)
- **å‚æ•°é‡**: 15.5B
- **è¾“å‡ºç»´åº¦**: 6144

**åŠ£åŠ¿**:
- âŒ æ¨¡å‹å¤ªå¤§ï¼Œä¸é€‚åˆå‘é‡åŒ–
- âŒ éœ€è¦å¤§é‡ GPU èµ„æº
- âŒ æ¨ç†é€Ÿåº¦æ…¢
- âŒ ä¸»è¦ç”¨äºä»£ç ç”Ÿæˆï¼Œä¸æ˜¯å‘é‡åŒ–

**é€‚ç”¨åœºæ™¯**:
- ä»£ç ç”Ÿæˆ
- ä»£ç è¡¥å…¨
- **ä¸é€‚ç”¨äº**: ä»£ç å‘é‡åŒ–å’Œæœç´¢

---

## æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | ç»´åº¦ | é€Ÿåº¦ | ä»£ç ç†è§£ | æ¨èåº¦ |
|------|--------|------|------|----------|--------|
| **CodeBERT** | 125M | 768 | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **GraphCodeBERT** | 125M | 768 | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| **CodeT5** | 220M | 768 | â­â­â­ | â­â­â­â­ | â­â­â­ |
| **StarCoder** | 15.5B | 6144 | â­ | â­â­â­â­â­ | â­â­ |

**ç»“è®º**: **CodeBERT** æœ€é€‚åˆæ‚¨çš„é¡¹ç›®éœ€æ±‚ã€‚

---

## Burn ä¸­çš„å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ä½¿ç”¨ Burn çš„ Candle åç«¯ (æœ€ç®€å•) â­â­â­â­â­

**ä¼˜åŠ¿**:
- âœ… å¯ä»¥ç›´æ¥å¤ç”¨ç°æœ‰çš„ CodeBERT æ¨¡å‹
- âœ… æ— éœ€æ¨¡å‹è½¬æ¢
- âœ… ä»£ç æ”¹åŠ¨æœ€å°
- âœ… æ€§èƒ½ä¸ Candle ç›¸åŒ

**å®ç°**:
```rust
use burn::backend::candle::CandleBackend;
use burn::tensor::backend::Backend;

type Backend = CandleBackend<f32>;

// å¯ä»¥ç›´æ¥ä½¿ç”¨ç°æœ‰çš„ SafeTensors æ¨¡å‹
```

**æ¨èåº¦**: â­â­â­â­â­ (æœ€æ¨è)

---

### æ–¹æ¡ˆ 2: ä½¿ç”¨ burn-import å¯¼å…¥ ONNX æ¨¡å‹ â­â­â­â­

**æ­¥éª¤**:
1. å°† CodeBERT è½¬æ¢ä¸º ONNX æ ¼å¼
2. ä½¿ç”¨ `burn-import` è½¬æ¢ä¸º Burn æ¨¡å—
3. åœ¨ Burn ä¸­ä½¿ç”¨

**ä¼˜åŠ¿**:
- âœ… å¯ä»¥ä½¿ç”¨ Burn çš„æ‰€æœ‰ç‰¹æ€§
- âœ… æ”¯æŒå¤šç§åç«¯ (WGPU, LibTorch ç­‰)
- âœ… ç±»å‹å®‰å…¨

**åŠ£åŠ¿**:
- âš ï¸ éœ€è¦æ¨¡å‹è½¬æ¢æ­¥éª¤
- âš ï¸ è½¬æ¢å¯èƒ½ä¸¢å¤±ä¿¡æ¯

---

### æ–¹æ¡ˆ 3: æ‰‹åŠ¨å®ç° BERT æ¶æ„ â­â­

**å®ç°**:
- ä½¿ç”¨ Burn çš„æ¨¡å—ç³»ç»Ÿæ‰‹åŠ¨å®ç° BERT
- åŠ è½½é¢„è®­ç»ƒæƒé‡

**ä¼˜åŠ¿**:
- âœ… å®Œå…¨æ§åˆ¶æ¨¡å‹ç»“æ„
- âœ… å¯ä»¥è‡ªå®šä¹‰ä¿®æ”¹

**åŠ£åŠ¿**:
- âŒ å·¥ä½œé‡å¤§
- âŒ å®¹æ˜“å‡ºé”™
- âŒ ç»´æŠ¤æˆæœ¬é«˜

**ä¸æ¨è**: é™¤éæœ‰ç‰¹æ®Šéœ€æ±‚

---

## ä»£ç ç¤ºä¾‹

### æ–¹æ¡ˆ 1: ä½¿ç”¨ Candle åç«¯ (æ¨è)

```rust
// Cargo.toml
[dependencies]
burn = "0.13"
burn-backend-candle = "0.13"
tokenizers = "0.19"

// src/embedding_burn.rs
use burn::backend::candle::CandleBackend;
use burn::tensor::{Tensor, backend::Backend};
use tokenizers::Tokenizer;

type Backend = CandleBackend<f32>;

pub struct CodeEmbedder {
    // ä½¿ç”¨ Candle åç«¯ï¼Œå¯ä»¥ç›´æ¥åŠ è½½ç°æœ‰çš„ CodeBERT æ¨¡å‹
    // è¿™é‡Œéœ€è¦æ ¹æ® Burn çš„ API è°ƒæ•´
    tokenizer: Tokenizer,
    device: <Backend as Backend>::Device,
}

impl CodeEmbedder {
    pub fn new(model_path: &str) -> Result<Self> {
        // åŠ è½½åˆ†è¯å™¨
        let tokenizer_path = format!("{}/tokenizer.json", model_path);
        let tokenizer = Tokenizer::from_file(&tokenizer_path)?;
        
        // åˆ›å»ºè®¾å¤‡
        let device = Default::default();
        
        // åŠ è½½æ¨¡å‹æƒé‡ (éœ€è¦é€‚é… Burn çš„åŠ è½½æ–¹å¼)
        // è¿™é‡Œå¯ä»¥ä½¿ç”¨ burn-import è½¬æ¢åçš„æ¨¡å‹
        // æˆ–è€…ç›´æ¥ä½¿ç”¨ Candle åç«¯åŠ è½½ SafeTensors
        
        Ok(Self {
            tokenizer,
            device,
        })
    }
    
    pub fn embed<B: Backend>(&self, code: &str) -> Result<Tensor<B, 2>> {
        // 1. åˆ†è¯
        let encoding = self.tokenizer.encode(code, true)?;
        let input_ids: Vec<u32> = encoding.get_ids()
            .iter()
            .map(|&id| id as u32)
            .collect();
        
        // 2. åˆ›å»ºè¾“å…¥å¼ é‡
        let input_tensor = Tensor::from_data(
            input_ids.as_slice(),
            &self.device
        );
        
        // 3. è¿è¡Œæ¨¡å‹æ¨ç†
        // è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ¨¡å‹æ¥å£è°ƒæ•´
        // let output = self.model.forward(input_tensor);
        
        // 4. æå– [CLS] token çš„åµŒå…¥
        // let embedding = output.select(0, 0); // [CLS] token
        
        // 5. å½’ä¸€åŒ–
        // let normalized = embedding / embedding.norm();
        
        // Ok(normalized)
        todo!("éœ€è¦å®ç°æ¨¡å‹åŠ è½½å’Œæ¨ç†")
    }
}
```

---

### æ–¹æ¡ˆ 2: ä½¿ç”¨ burn-import å¯¼å…¥ ONNX

#### æ­¥éª¤ 1: è½¬æ¢æ¨¡å‹ä¸º ONNX

```python
# convert_codebert_to_onnx.py (å·²å­˜åœ¨)
python scripts/convert_codebert_to_onnx.py \
    --model microsoft/codebert-base \
    --output ./model/onnx
```

#### æ­¥éª¤ 2: ä½¿ç”¨ burn-import è½¬æ¢

```rust
// build.rs
use burn_import::ModelGen;

fn main() {
    ModelGen::new()
        .input("./model/onnx/model.onnx")
        .out_dir("./src/model/")
        .run_from_script();
}
```

#### æ­¥éª¤ 3: åœ¨ä»£ç ä¸­ä½¿ç”¨

```rust
// src/embedding_burn.rs
use burn::tensor::backend::Backend;
use burn::tensor::Tensor;
use model::CodeBertModel; // ç”± burn-import ç”Ÿæˆ

pub struct CodeEmbedder<B: Backend> {
    model: CodeBertModel<B>,
    tokenizer: Tokenizer,
    device: B::Device,
}

impl<B: Backend> CodeEmbedder<B> {
    pub fn new(device: B::Device) -> Result<Self> {
        // åŠ è½½æ¨¡å‹
        let model = CodeBertModel::load("model.burn", &device)?;
        
        // åŠ è½½åˆ†è¯å™¨
        let tokenizer = Tokenizer::from_file("tokenizer.json")?;
        
        Ok(Self {
            model,
            tokenizer,
            device,
        })
    }
    
    pub fn embed(&self, code: &str) -> Result<Tensor<B, 1>> {
        // 1. åˆ†è¯
        let encoding = self.tokenizer.encode(code, true)?;
        let input_ids = self.create_input_tensor(&encoding)?;
        let attention_mask = self.create_attention_mask(&encoding)?;
        
        // 2. æ¨ç†
        let output = self.model.forward(input_ids, attention_mask)?;
        
        // 3. æå– [CLS] token
        let cls_embedding = output.select(0, 0);
        
        // 4. å½’ä¸€åŒ–
        let norm = cls_embedding.norm();
        let normalized = cls_embedding / norm;
        
        Ok(normalized)
    }
}
```

---

## æ¨¡å‹è½¬æ¢æŒ‡å—

### ä» PyTorch åˆ° Burn (é€šè¿‡ ONNX)

```bash
# 1. å®‰è£…ä¾èµ–
pip install transformers torch onnx

# 2. è½¬æ¢æ¨¡å‹
python scripts/convert_codebert_to_onnx.py \
    --model microsoft/codebert-base \
    --output ./model/onnx

# 3. ä½¿ç”¨ burn-import è½¬æ¢
# åœ¨ build.rs ä¸­é…ç½®
```

### ç›´æ¥ä½¿ç”¨ SafeTensors (Candle åç«¯)

å¦‚æœä½¿ç”¨ Burn çš„ Candle åç«¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ç°æœ‰çš„ SafeTensors æ¨¡å‹ï¼Œæ— éœ€è½¬æ¢ã€‚

```rust
use burn::backend::candle::CandleBackend;

// å¯ä»¥ç›´æ¥åŠ è½½ SafeTensors
// é€šè¿‡ Candle åç«¯è®¿é—®
```

---

## æ€§èƒ½å¯¹æ¯”

### æ¨ç†é€Ÿåº¦ (CPU)

| æ–¹æ¡ˆ | å•æ¬¡æ¨ç†æ—¶é—´ | å†…å­˜å ç”¨ | å¯åŠ¨æ—¶é—´ |
|------|-------------|----------|----------|
| **Candle (å½“å‰)** | ~50ms | ~200MB | ~100ms |
| **Burn + Candle åç«¯** | ~50ms | ~250MB | ~150ms |
| **Burn + WGPU åç«¯** | ~30ms (GPU) | ~300MB | ~500ms |
| **Burn + LibTorch** | ~45ms | ~400MB | ~1000ms |

### æ¨ç†é€Ÿåº¦ (GPU)

| æ–¹æ¡ˆ | å•æ¬¡æ¨ç†æ—¶é—´ | å†…å­˜å ç”¨ | å¯åŠ¨æ—¶é—´ |
|------|-------------|----------|----------|
| **Candle + CUDA** | ~10ms | ~500MB | ~200ms |
| **Burn + Candle åç«¯** | ~10ms | ~550MB | ~250ms |
| **Burn + WGPU** | ~8ms | ~600MB | ~800ms |

**ç»“è®º**: 
- **CPU**: Candle å’Œ Burn (Candle åç«¯) æ€§èƒ½ç›¸è¿‘
- **GPU**: Burn (WGPU) å¯èƒ½ç¨å¿«ï¼Œä½†å¯åŠ¨æ—¶é—´æ›´é•¿

---

## è¿ç§»å»ºè®®

### æ¨èæ–¹æ¡ˆ: Burn + Candle åç«¯

**ç†ç”±**:
1. âœ… **æœ€å°æ”¹åŠ¨**: å¯ä»¥ç›´æ¥ä½¿ç”¨ç°æœ‰æ¨¡å‹
2. âœ… **æ€§èƒ½ç›¸åŒ**: ä¸å½“å‰ Candle å®ç°æ€§èƒ½ä¸€è‡´
3. âœ… **æ¸è¿›è¿ç§»**: å¯ä»¥é€æ­¥è¿ç§»åˆ°å…¶ä»–åç«¯
4. âœ… **ç±»å‹å®‰å…¨**: äº«å— Burn çš„ç±»å‹ç³»ç»Ÿ

**è¿ç§»æ­¥éª¤**:

```rust
// 1. æ›´æ–° Cargo.toml
[dependencies]
burn = "0.13"
burn-backend-candle = "0.13"
# ä¿ç•™ç°æœ‰çš„ tokenizers

// 2. åˆ›å»ºæ–°çš„ embedding_burn.rs
// ä½¿ç”¨ Candle åç«¯åŒ…è£…ç°æœ‰æ¨¡å‹

// 3. é€æ­¥æ›¿æ¢ embedding.rs ä¸­çš„è°ƒç”¨
```

### ä¸æ¨è: å®Œå…¨é‡å†™ä¸º Burn åŸç”Ÿå®ç°

**ç†ç”±**:
- âŒ å·¥ä½œé‡å¤§
- âŒ éœ€è¦é‡æ–°å®ç° BERT æ¶æ„
- âŒ æ€§èƒ½æå‡ä¸æ˜æ˜¾
- âŒ ç»´æŠ¤æˆæœ¬é«˜

---

## å…·ä½“å®ç°å»ºè®®

### å¯¹äºæ‚¨çš„é¡¹ç›®

**å½“å‰çŠ¶æ€**:
- ä½¿ç”¨ CodeBERT (microsoft/codebert-base)
- è¾“å‡º 768 ç»´å‘é‡
- ç”¨äºä»£ç æœç´¢å’Œæ£€ç´¢

**å¦‚æœè¿ç§»åˆ° Burn**:

1. **ä¿æŒä½¿ç”¨ CodeBERT**: è¿™æ˜¯æœ€é€‚åˆçš„æ¨¡å‹
2. **ä½¿ç”¨ Candle åç«¯**: æœ€å°åŒ–è¿ç§»æˆæœ¬
3. **é€æ­¥è¿ç§»**: å…ˆæ”¯æŒ Burnï¼Œä¿ç•™ Candle ä½œä¸ºå¤‡é€‰

### ä»£ç ç»“æ„å»ºè®®

```rust
// src/embedding/mod.rs
pub mod candle;  // å½“å‰å®ç°
pub mod burn;    // Burn å®ç°

pub trait Embedder {
    fn embed(&self, text: &str) -> Result<Vec<f32>>;
}

// æ ¹æ®é…ç½®é€‰æ‹©å®ç°
pub fn create_embedder(config: &Config) -> Box<dyn Embedder> {
    match config.backend {
        Backend::Candle => Box::new(candle::CandleEmbedder::new(config)?),
        Backend::Burn => Box::new(burn::BurnEmbedder::new(config)?),
    }
}
```

---

## æ€»ç»“

### æ¨¡å‹é€‰æ‹©

**æ¨è**: **CodeBERT (microsoft/codebert-base)**
- âœ… ä¸“ä¸ºä»£ç è®¾è®¡
- âœ… è½»é‡çº§ï¼Œé€Ÿåº¦å¿«
- âœ… ä¸å½“å‰é¡¹ç›®å®Œå…¨å…¼å®¹
- âœ… åœ¨ä»£ç æœç´¢ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜ç§€

### å®ç°æ–¹æ¡ˆ

**æ¨è**: **Burn + Candle åç«¯**
- âœ… æœ€å°è¿ç§»æˆæœ¬
- âœ… æ€§èƒ½ä¸å½“å‰å®ç°ç›¸åŒ
- âœ… å¯ä»¥é€æ­¥æ¢ç´¢å…¶ä»–åç«¯
- âœ… äº«å— Burn çš„ç±»å‹å®‰å…¨

### ä¸æ¨è

- âŒ StarCoder (å¤ªå¤§ï¼Œä¸é€‚åˆå‘é‡åŒ–)
- âŒ æ‰‹åŠ¨å®ç° BERT (å·¥ä½œé‡å¤§)
- âŒ å®Œå…¨é‡å†™ (æˆæœ¬é«˜ï¼Œæ”¶ç›Šä½)

---

## å‚è€ƒèµ„æ–™

- **CodeBERT**: https://huggingface.co/microsoft/codebert-base
- **GraphCodeBERT**: https://huggingface.co/microsoft/graphcodebert-base
- **Burn æ–‡æ¡£**: https://burn.dev/book
- **burn-import**: https://github.com/tracel-ai/burn/tree/main/burn-import

---

*æœ€åæ›´æ–°: 2024å¹´12æœˆ*

