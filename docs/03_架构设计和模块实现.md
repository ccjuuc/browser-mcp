# 架构设计和模块实现

本文档详细介绍 Browser MCP Server 的架构设计和各个核心模块的实现原理。

## 1. 整体架构

### 1.1 架构图

```
┌─────────────────────────────────────────────────────────┐
│                    MCP Client                           │
│              (Claude Desktop / Cursor)                  │
└────────────────────┬────────────────────────────────────┘
                     │ JSON-RPC over stdio/HTTP
                     │
┌────────────────────▼────────────────────────────────────┐
│              MCPServer / HttpServer                     │
│  ┌──────────────────────────────────────────────────┐  │
│  │  - 请求路由                                       │  │
│  │  - JSON-RPC 协议处理                              │  │
│  │  - 工具调用分发                                   │  │
│  └──────────────────────────────────────────────────┘  │
└────────────────────┬────────────────────────────────────┘
                     │
┌────────────────────▼────────────────────────────────────┐
│            CodebaseIndexer (核心索引器)                 │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │
│  │  文本搜索    │  │  语义搜索    │  │  文件浏览    │ │
│  │  search_code │  │search_embed  │  │ list_files   │ │
│  └──────────────┘  └──────┬───────┘  └──────────────┘ │
└───────────────────────────┼────────────────────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
┌───────▼──────┐  ┌─────────▼────────┐  ┌──────▼───────┐
│ CodeParser   │  │    Embedder      │  │ QdrantStorage│
│ (Tree-sitter)│  │  (CodeBERT/TFIDF)│  │  (向量存储)  │
└──────────────┘  └──────────────────┘  └──────────────┘
```

### 1.2 分层架构

1. **协议层**：MCP 协议实现（stdio/HTTP）
2. **业务逻辑层**：CodebaseIndexer 提供核心功能
3. **服务层**：Parser、Embedder、Storage 等独立服务
4. **基础设施层**：配置、日志、状态管理

## 2. 核心模块详解

### 2.1 CodebaseIndexer（代码库索引器）

#### 2.1.1 职责

- 管理代码库路径和配置
- 协调文件扫描、解析、向量化、存储
- 提供搜索接口（文本搜索、语义搜索）

#### 2.1.2 数据结构

```rust
pub struct CodebaseIndexer {
    codebase_path: PathBuf,        // 代码库根路径
    config: CodebaseConfig,        // 配置信息
    embedder: Option<Embedder>,    // 向量化器（可选）
    qdrant: Option<Arc<QdrantStorage>>, // 向量数据库（可选）
}
```

#### 2.1.3 关键方法

**文件扫描**

```rust
pub async fn search_code(&self, query: &str, max_results: usize) -> Result<Vec<SearchResult>> {
    // 1. 构建正则表达式
    let regex = Regex::new(&regex::escape(&query))?;
    
    // 2. 使用 ignore crate 遍历文件（尊重 .gitignore）
    let walker = WalkBuilder::new(&codebase_path)
        .git_ignore(true)
        .build();
    
    // 3. 对每个文件进行搜索
    for entry in walker {
        // 过滤二进制文件、大文件等
        // 在文件中搜索匹配行
    }
    
    // 4. 返回结果
}
```

**代码切片**

```rust
pub async fn chunk_file(&self, file_path: &str) -> Result<Vec<CodeChunk>> {
    // 1. 读取文件内容
    let content = fs::read_to_string(&full_path).await?;
    
    // 2. 在阻塞线程中解析（Tree-sitter 是同步的）
    let chunks = tokio::task::spawn_blocking(move || {
        let mut parser = CodeParser::new();
        parser.parse_file(&path, &content, chunk_size)
    }).await??;
    
    // 3. 生成向量（如果启用）
    if let Some(ref embedder) = self.embedder {
        let embeddings = embedder.embed_batch(&texts).await?;
        // 将向量添加到 chunks
    }
    
    // 4. 返回代码块
}
```

**增量索引**

```rust
pub async fn index_codebase(&self) -> Result<()> {
    // 1. 加载索引状态
    let mut state = IndexerState::load(&state_path)?;
    
    // 2. 扫描所有文件
    let files_to_process = collect_files();
    
    // 3. 对每个文件
    for (path, modified_time, file_size) in files_to_process {
        // 检查是否需要索引
        if state.should_index(&path, modified_time, file_size) {
            // 切片和向量化
            let chunks = self.chunk_file(&path).await?;
            // 存储到 Qdrant
            qdrant.upsert_chunks(chunks).await?;
            // 更新状态
            state.update(path, modified_time, file_size);
        }
    }
    
    // 4. 保存状态
    state.save(&state_path)?;
}
```

### 2.2 CodeParser（代码解析器）

#### 2.2.1 职责

- 识别代码文件的编程语言
- 使用 Tree-sitter 解析代码
- 提取语义单元（函数、类、方法等）

#### 2.2.2 语言识别

```rust
impl LanguageType {
    pub fn from_path(path: &Path) -> Self {
        if let Some(ext) = path.extension() {
            match ext.to_string_lossy().to_lowercase().as_str() {
                "rs" => Self::Rust,
                "js" | "jsx" => Self::JavaScript,
                "ts" | "tsx" => Self::TypeScript,
                "py" => Self::Python,
                // ...
                _ => Self::Unknown,
            }
        } else {
            Self::Unknown
        }
    }
}
```

#### 2.2.3 解析流程

```rust
pub fn parse_file(&mut self, file_path: &Path, content: &str, max_chunk_size: usize) -> Result<Vec<CodeChunk>> {
    // 1. 识别语言
    let lang_type = LanguageType::from_path(file_path);
    
    // 2. 获取 Tree-sitter 语言对象
    let language = lang_type.get_language()?;
    
    // 3. 设置语言并解析
    self.parser.set_language(&language)?;
    let tree = self.parser.parse(content, None)?;
    
    // 4. 提取代码块
    Self::extract_chunks(file_path, content, &tree, lang_type, max_chunk_size)
}
```

#### 2.2.4 代码块提取

```rust
fn extract_chunks(...) -> Result<Vec<CodeChunk>> {
    let target_node_types = match lang_type {
        LanguageType::Rust => vec!["function_item", "struct_item", "enum_item"],
        LanguageType::JavaScript => vec!["function_declaration", "class_declaration"],
        // ...
    };
    
    // 遍历语法树
    let mut stack = vec![root_node];
    while let Some(node) = stack.pop() {
        if target_node_types.contains(&node.kind()) {
            // 提取代码块
            let chunk = extract_code_chunk(&node, content);
            chunks.push(chunk);
        } else {
            // 继续遍历子节点
            stack.extend(node.children());
        }
    }
}
```

**关键设计点**：

- **迭代遍历**：使用栈而不是递归，避免栈溢出
- **大小限制**：如果代码块太大，继续分割
- **降级策略**：如果解析失败，使用简单的行切片

### 2.3 Embedder（向量化器）

#### 2.3.1 职责

- 将代码文本转换为向量嵌入
- 支持两种方式：CodeBERT 模型或 TF-IDF

#### 2.3.2 模型向量化

```rust
#[cfg(feature = "model-embedding")]
async fn embed_with_model(&self, text: &str, model: Arc<BertModel>, tokenizer: &Arc<Tokenizer>) -> Result<Vec<f32>> {
    // 在阻塞线程中运行（模型推理是 CPU/GPU 密集型）
    tokio::task::spawn_blocking(move || {
        // 1. 分词
        let encoding = tokenizer.encode(text, true)?;
        let input_ids = encoding.get_ids();
        
        // 2. 创建输入张量
        let input_ids_tensor = Tensor::new(input_ids, &device)?.unsqueeze(0)?;
        let attention_mask = create_attention_mask(&input_ids);
        
        // 3. 模型前向传播
        let hidden_states = model.forward(&input_ids_tensor, &token_type_ids, Some(&attention_mask))?;
        
        // 4. 提取 [CLS] token 嵌入（第一个 token）
        let cls_embedding = hidden_states.get(0)?.get(0)?;
        
        // 5. 归一化
        normalize(cls_embedding.to_vec1::<f32>()?)
    }).await?
}
```

#### 2.3.3 TF-IDF 向量化（降级方案）

```rust
async fn embed_tfidf(&self, text: &str) -> Result<Vec<f32>> {
    // 1. 简单分词
    let tokens = Self::tokenize(text);
    
    // 2. 使用哈希将 token 映射到向量维度
    let mut vector = vec![0.0; self.config.dimension];
    for token in tokens {
        let hash = Self::hash_token(&token);
        let index = hash % self.config.dimension;
        vector[index] += 1.0;
    }
    
    // 3. 归一化
    normalize(vector)
}
```

**TF-IDF 的特点**：

- **简单**：不需要模型文件
- **快速**：只是哈希和计数
- **内存占用小**：不需要加载大模型
- **语义理解弱**：只是词频统计

#### 2.3.4 批量向量化

```rust
pub async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>> {
    if let (Some(ref model), Some(ref tokenizer)) = (&self.model, &self.tokenizer) {
        // 使用模型批量处理
        let mut embeddings = Vec::new();
        for text in texts {
            embeddings.push(self.embed_with_model(text, Arc::clone(model), tokenizer).await?);
        }
        Ok(embeddings)
    } else {
        // 使用 TF-IDF
        // ...
    }
}
```

### 2.4 QdrantStorage（向量存储）

#### 2.4.1 职责

- 管理 Qdrant 连接
- 存储代码块向量
- 执行向量相似度搜索

#### 2.4.2 初始化

```rust
pub async fn init(&self) -> Result<()> {
    // 检查集合是否存在
    if !self.client.collection_exists(&self.collection_name).await? {
        // 创建集合
        self.client.create_collection(CreateCollection {
            collection_name: self.collection_name.clone(),
            vectors_config: Some(VectorsConfig {
                config: Some(VectorParams {
                    size: self.vector_size,      // 向量维度（768）
                    distance: Distance::Cosine,  // 余弦相似度
                }),
            }),
        }).await?;
    }
    Ok(())
}
```

#### 2.4.3 插入向量

```rust
pub async fn upsert_chunks(&self, chunks: Vec<CodeChunk>) -> Result<()> {
    // 1. 转换代码块为向量点
    let points: Vec<PointStruct> = chunks
        .into_iter()
        .filter_map(|chunk| {
            if let Some(embedding) = chunk.embedding {
                // 创建唯一 ID
                let unique_key = format!("{}:{}", chunk.file_path, chunk.start_byte);
                let id = Uuid::new_v5(&Uuid::NAMESPACE_URL, unique_key.as_bytes());
                
                // 创建元数据
                let payload = json!({
                    "file_path": chunk.file_path,
                    "content": chunk.content,
                    // ...
                });
                
                Some(PointStruct::new(id.to_string(), embedding, payload))
            } else {
                None
            }
        })
        .collect();
    
    // 2. 批量插入
    self.client.upsert_points(UpsertPoints {
        collection_name: self.collection_name.clone(),
        points,
    }).await?;
    
    Ok(())
}
```

#### 2.4.4 向量搜索

```rust
pub async fn search(&self, vector: Vec<f32>, limit: u64) -> Result<Vec<(CodeChunk, f32)>> {
    // 1. 搜索相似向量
    let search_result = self.client.search_points(SearchPoints {
        collection_name: self.collection_name.clone(),
        vector,
        limit,
        with_payload: Some(true.into()),
    }).await?;
    
    // 2. 转换结果为代码块
    let mut results = Vec::new();
    for point in search_result.result {
        let score = point.score;  // 相似度分数（0-1）
        let payload = point.payload;
        
        // 从 payload 重构 CodeChunk
        let chunk = CodeChunk {
            file_path: payload.get("file_path")?.as_str()?.to_string(),
            content: payload.get("content")?.as_str()?.to_string(),
            // ...
        };
        
        results.push((chunk, score));
    }
    
    Ok(results)
}
```

### 2.5 MCPServer（MCP 协议服务器）

#### 2.5.1 职责

- 处理 JSON-RPC 请求
- 实现 MCP 协议规范
- 分发工具调用

#### 2.5.2 协议处理

```rust
pub async fn run(&self) -> Result<()> {
    let mut stdin_reader = BufReader::new(tokio::io::stdin());
    let mut stdout_writer = tokio::io::stdout();
    
    loop {
        // 1. 读取 JSON-RPC 请求
        let mut buffer = String::new();
        stdin_reader.read_line(&mut buffer).await?;
        
        // 2. 解析请求
        let request: MCPRequest = serde_json::from_str(&buffer)?;
        
        // 3. 处理请求
        let response = self.handle_request(&request).await?;
        
        // 4. 发送响应
        let response_json = serde_json::to_string(&response)?;
        stdout_writer.write_all(response_json.as_bytes()).await?;
        stdout_writer.write_all(b"\n").await?;
        stdout_writer.flush().await?;
    }
}
```

#### 2.5.3 工具调用分发

```rust
async fn handle_tool_call(&self, id: Option<Value>, params: Option<Value>) -> Result<MCPResponse> {
    let tool_name = params.get("name")?.as_str()?;
    let arguments = params.get("arguments");
    
    match tool_name {
        "search_code" => {
            let query = arguments.get("query")?.as_str()?;
            let results = self.indexer.search_code(query, max_results).await?;
            // 返回结果
        }
        "search_by_embedding" => {
            let query = arguments.get("query")?.as_str()?;
            let results = self.indexer.search_by_embedding(query, max_results).await?;
            // 返回结果和相似度分数
        }
        "read_file" => {
            let file_path = arguments.get("file_path")?.as_str()?;
            let content = self.indexer.read_file(file_path).await?;
            // 返回文件内容
        }
        // ...
    }
}
```

### 2.6 HttpServer（HTTP 服务器）

#### 2.6.1 职责

- 提供 HTTP 接口
- 将 HTTP 请求转换为 MCP 请求
- 支持跨域（CORS）

#### 2.6.2 实现

```rust
pub async fn run(self) -> Result<()> {
    let app = Router::new()
        .route("/", post(handle_mcp_request))    // MCP 端点
        .route("/health", get(health_check))     // 健康检查
        .layer(CorsLayer::new().allow_origin(Any))
        .with_state(self.indexer);
    
    let listener = TcpListener::bind(("0.0.0.0", self.port)).await?;
    axum::serve(listener, app).await?;
    Ok(())
}
```

## 3. 数据流

### 3.1 索引流程

```
文件系统
  │
  ├─> 文件扫描 (WalkBuilder)
  │     │
  │     ├─> 过滤 (扩展名、大小、.gitignore)
  │     │
  │     └─> 检查索引状态
  │           │
  │           ├─> 已索引且未变更 → 跳过
  │           │
  │           └─> 需要索引
  │                 │
  │                 ├─> CodeParser (Tree-sitter)
  │                 │     │
  │                 │     └─> 生成 CodeChunk[]
  │                 │
  │                 ├─> Embedder
  │                 │     │
  │                 │     ├─> 模型路径存在 → CodeBERT
  │                 │     │
  │                 │     └─> 否则 → TF-IDF
  │                 │           │
  │                 │           └─> 生成向量
  │                 │
  │                 └─> QdrantStorage
  │                       │
  │                       └─> 存储向量和元数据
  │
  └─> 更新索引状态
```

### 3.2 搜索流程

**文本搜索**：
```
用户查询
  │
  └─> 正则表达式匹配
        │
        └─> 文件遍历
              │
              └─> 行匹配
                    │
                    └─> 返回结果
```

**语义搜索**：
```
用户查询
  │
  └─> Embedder.embed(query)
        │
        └─> 生成查询向量
              │
              └─> QdrantStorage.search(vector)
                    │
                    └─> 余弦相似度计算
                          │
                          └─> 返回最相似的代码块
```

## 4. 配置管理

### 4.1 配置加载优先级

1. 环境变量 `BROWSER_MCP_CONFIG`
2. 当前目录的 `browser-mcp.toml`
3. 用户配置目录的 `browser-mcp/config.toml`
4. 默认配置

### 4.2 配置结构

```toml
[codebase]
path = "/path/to/codebase"
ignored_extensions = ["png", "jpg", ...]
max_file_size = 1_000_000
chunk_size = 2000
enable_chunking = true
enable_embedding = true

[server]
log_level = "info"
max_results = 50

[embedding]
dimension = 768
model_path = "./model"
tokenizer_path = "./model/tokenizer.json"
max_length = 512

[qdrant]
url = "http://localhost:6334"
collection_name = "browser-mcp"
```

## 5. 错误处理

### 5.1 错误处理策略

- **使用 anyhow**：统一的错误类型，简化错误传播
- **上下文信息**：使用 `with_context` 添加错误上下文
- **优雅降级**：模型加载失败时降级到 TF-IDF

### 5.2 常见错误场景

1. **文件读取失败**：记录日志，跳过该文件
2. **解析失败**：降级到行切片
3. **模型加载失败**：降级到 TF-IDF
4. **Qdrant 不可用**：禁用向量搜索，只支持文本搜索

## 6. 并发和性能

### 6.1 异步设计

- **Tokio 运行时**：所有 I/O 操作都是异步的
- **阻塞任务隔离**：Tree-sitter 和模型推理在 `spawn_blocking` 中运行
- **后台任务**：索引任务在后台运行，不阻塞服务器

### 6.2 性能优化

- **增量索引**：只处理变更文件
- **批量操作**：批量向量化和批量插入
- **状态持久化**：定期保存索引状态，减少 I/O

## 7. 总结

Browser MCP Server 采用分层、模块化的架构设计：

1. **清晰的职责分离**：每个模块专注于单一职责
2. **灵活的扩展性**：可以轻松添加新的语言支持、搜索方式等
3. **优雅的降级**：在组件不可用时自动降级
4. **高性能**：异步 I/O 和增量处理保证性能

